{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LSTM_Learning_Lib import Model\n",
    "from FeatureSetCalculation_Lib import ComputeMultiLevelLogsig1dBM\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from GetSeqMnistData import GetSeqPenandCalLogSig, GetSeqPenDigit,GetSeqPenNormCalLogSig,GetSeqPenNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters grid\n",
    "param_grid = {'deg_of_sig': [2,3,4,5,6], 'number_of_segment': [8],\n",
    "'learning_rate': [0.001]}\n",
    "Param = list(ParameterGrid(param_grid))\n",
    "# Parameters\n",
    "training_iters = 60\n",
    "batch_size = 200\n",
    "\n",
    "sig_comp_time = []\n",
    "test_result = []\n",
    "test_time = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train RNN with different feature sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.size(Param)):\n",
    "    # Raw data feature set generator\n",
    "    if Param[i]['deg_of_sig']==0:\n",
    "        start = time.time()\n",
    "        train_X, train_Y = GetSeqPenDigit('pendigits-orig.tra.txt')\n",
    "        test_X, test_Y = GetSeqPenDigit('pendigits-orig.tes.txt')\n",
    "        trainsampleClip = len(train_Y)\n",
    "        testsampleClip = len(test_Y)\n",
    "        max_interval = 0\n",
    "        for j in range(trainsampleClip):\n",
    "            if max_interval < len(train_X[j]):\n",
    "                max_interval = len(train_X[j])\n",
    " \n",
    "        for j in range(testsampleClip):\n",
    "            if max_interval < len(test_X[j]):\n",
    "                max_interval = len(test_X[j])\n",
    "\n",
    "        n_input = int(max_interval/Param[i]['number_of_segment'])+1\n",
    "        if n_input % 2 != 0:\n",
    "            n_input += 1\n",
    "        train_data = np.zeros((trainsampleClip, n_input*Param[i]['number_of_segment']))\n",
    "        test_data = np.zeros((testsampleClip, n_input*Param[i]['number_of_segment']))\n",
    "        for sn in range(trainsampleClip):\n",
    "            tmplen = len(train_X[sn])\n",
    "            train_data[sn, :tmplen] = train_X[sn][:]\n",
    "        for sn in range(testsampleClip):\n",
    "            tmplen = len(test_X[sn])\n",
    "            test_data[sn, :tmplen] = test_X[sn][:]\n",
    "        train_data = train_data.reshape(trainsampleClip, Param[i]['number_of_segment'], n_input)\n",
    "        test_data = test_data.reshape(testsampleClip, Param[i]['number_of_segment'], n_input)\n",
    "        elapsed = time.time()-start\n",
    "        sig_comp_time.append(elapsed)\n",
    "        model3 = Model( Param[i]['learning_rate'], training_iters, batch_size, n_input, Param[i]['number_of_segment'], Param[i]['deg_of_sig'], train_data, train_Y, test_data, test_Y)\n",
    "    # Folded raw data feature set generator\n",
    "    elif Param[i]['deg_of_sig']==1:\n",
    "        start = time.time()\n",
    "        train_X, train_Y = GetSeqPenDigit('pendigits-orig.tra.txt')\n",
    "        test_X, test_Y = GetSeqPenDigit('pendigits-orig.tes.txt')\n",
    "        trainsampleClip = len(train_Y)\n",
    "        testsampleClip = len(test_Y)\n",
    "        max_interval = 0\n",
    "        \n",
    "        train_increment = [[] for k in range(trainsampleClip)]\n",
    "        test_increment = [[] for k in range(testsampleClip)]\n",
    "        for x in train_X:\n",
    "            if max_interval < len(x):\n",
    "                max_interval = len(x)\n",
    "        for x in test_X:\n",
    "            if max_interval < len(x):\n",
    "                max_interval = len(x)\n",
    "        print(max_interval)\n",
    "        train_data = np.zeros((trainsampleClip, max_interval))\n",
    "        test_data = np.zeros((testsampleClip, max_interval))\n",
    "        for sn in range(trainsampleClip):\n",
    "            tmplen = len(train_X[sn])\n",
    "            train_data[sn, :tmplen] = train_X[sn][:]\n",
    "        for sn in range(testsampleClip):\n",
    "            tmplen = len(test_X[sn])\n",
    "            test_data[sn, :tmplen] = test_X[sn][:]\n",
    "        n_input = 2\n",
    "        train_data = train_data.reshape(trainsampleClip, int(max_interval/2), 2)\n",
    "        test_data = test_data.reshape(testsampleClip, int(max_interval/2), 2)\n",
    "        print(train_data[0])\n",
    "        elapsed = time.time()-start\n",
    "        sig_comp_time.append(elapsed)\n",
    "        model3 = Model( Param[i]['learning_rate'], training_iters, batch_size,  n_input, int(max_interval/2), Param[i]['deg_of_sig'], train_data, train_Y, test_data, test_Y)\n",
    "\n",
    "    # Logsig feature set generator\n",
    "    else:\n",
    "        start = time.time()\n",
    "        X_logsig_start, Y = GetSeqPenandCalLogSig(Param[i]['deg_of_sig'], Param[i]['number_of_segment'],'pendigits-orig.tra.txt')\n",
    "        test_X_logsig_start, test_Y = GetSeqPenandCalLogSig(Param[i]['deg_of_sig'], Param[i]['number_of_segment'],'pendigits-orig.tes.txt')\n",
    "        print(X_logsig_start.shape)\n",
    "        print(test_X_logsig_start.shape)\n",
    "        n_input = np.shape(X_logsig_start)[2]\n",
    "        # number_of_samples = np.shape(X_logsig_start)[0]\n",
    "        elapsed = time.time()-start\n",
    "        sig_comp_time.append(elapsed)\n",
    "        model3 = Model( Param[i]['learning_rate'], training_iters, batch_size, n_input, Param[i]['number_of_segment'], Param[i]['deg_of_sig'], X_logsig_start, Y, test_X_logsig_start, test_Y)\n",
    "    \n",
    "    # Model built and train\n",
    "    fixed_error_result_model3 = model3.BuildModelKerasMn()\n",
    "\n",
    "    print(\"Time = \" + str(time.time()-start))\n",
    "    print(\"Testing loss = \" + str(fixed_error_result_model3['Loss']))\n",
    "    # model3.KerasPredict()\n",
    "    test_result.append(fixed_error_result_model3 ['Loss'])\n",
    "    test_time.append(fixed_error_result_model3 ['Time'])\n",
    "    \n",
    "    # results save\n",
    "    np.save('error_tol'+str(error_tol)+'deg_logsig'+str(Param[i]['deg_of_sig'])+'_test_result', test_result)\n",
    "    np.save('error_tol'+str(error_tol)+'deg_logsig'+str(Param[i]['deg_of_sig'])+'_test_time', test_time)\n",
    "    np.save('error_tol'+str(error_tol)+'deg_logsig'+str(Param[i]['deg_of_sig'])+'_sig_comp_time', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_time)\n",
    "print(test_result)\n",
    "print(sig_comp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
